<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Journey from 8xlarge to 2xlarge | Software hacks in small packs</title>
<meta name=keywords content="aws,performance,pos,postgresql"><meta name=description content="There are only 2 ways to make money. Increase your income or reduce your expense. Its true for inidividual as well as organizations. In my current organization we were facing huge challenge of unncessary cost being spent on AWS. We were paying huge chunk of our income to AWS. In this post I am going to disect some critical problems and optimizations done to reduce the cost of the AWS."><meta name=author content><link rel=canonical href=https://rupeshsharma.in/posts/journey-from-8xlarge-to-2xlarge/><link crossorigin=anonymous href=https://rupeshsharma.in/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://rupeshsharma.in/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://rupeshsharma.in/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://rupeshsharma.in/favicon-32x32.png><link rel=apple-touch-icon href=https://rupeshsharma.in/apple-touch-icon.png><link rel=mask-icon href=https://rupeshsharma.in/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://rupeshsharma.in/posts/journey-from-8xlarge-to-2xlarge/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://rupeshsharma.in/posts/journey-from-8xlarge-to-2xlarge/"><meta property="og:site_name" content="Software hacks in small packs"><meta property="og:title" content="Journey from 8xlarge to 2xlarge"><meta property="og:description" content="There are only 2 ways to make money. Increase your income or reduce your expense. Its true for inidividual as well as organizations. In my current organization we were facing huge challenge of unncessary cost being spent on AWS. We were paying huge chunk of our income to AWS. In this post I am going to disect some critical problems and optimizations done to reduce the cost of the AWS."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-23T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-23T00:00:00+00:00"><meta property="article:tag" content="Aws"><meta property="article:tag" content="Performance"><meta property="article:tag" content="Pos"><meta property="article:tag" content="Postgresql"><meta name=twitter:card content="summary"><meta name=twitter:title content="Journey from 8xlarge to 2xlarge"><meta name=twitter:description content="There are only 2 ways to make money. Increase your income or reduce your expense. Its true for inidividual as well as organizations. In my current organization we were facing huge challenge of unncessary cost being spent on AWS. We were paying huge chunk of our income to AWS. In this post I am going to disect some critical problems and optimizations done to reduce the cost of the AWS."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://rupeshsharma.in/posts/"},{"@type":"ListItem","position":2,"name":"Journey from 8xlarge to 2xlarge","item":"https://rupeshsharma.in/posts/journey-from-8xlarge-to-2xlarge/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Journey from 8xlarge to 2xlarge","name":"Journey from 8xlarge to 2xlarge","description":"There are only 2 ways to make money. Increase your income or reduce your expense. Its true for inidividual as well as organizations. In my current organization we were facing huge challenge of unncessary cost being spent on AWS. We were paying huge chunk of our income to AWS. In this post I am going to disect some critical problems and optimizations done to reduce the cost of the AWS.\n","keywords":["aws","performance","pos","postgresql"],"articleBody":"There are only 2 ways to make money. Increase your income or reduce your expense. Its true for inidividual as well as organizations. In my current organization we were facing huge challenge of unncessary cost being spent on AWS. We were paying huge chunk of our income to AWS. In this post I am going to disect some critical problems and optimizations done to reduce the cost of the AWS.\nThe Begining\nAfter realising the problem we formed a team who can solely focus on the AWS cost optimization. I was part of this team and my job was to find out critical bottlenecks and solve them.\nWe started with checking our AWS bills and found that majority of cost was contributed by RDS. And that was very evident as we were using RDS 8xlarge machine to process daily of 13K applications. So we shifted our focus on optimizing RDS usage.\n**Milestone 1\n**We started checking AWS performance insight to get the idea what things are consuming most of RDS CPU. Found that top 10 queries were few functions which are heavily used by the system. To solve this problem we decided to convert these functions procedures to java code.\nWe wanted to set some benchmark to verify our changes. So we did a performace setup to validate our changes. And tested it against the current code. Then we started converting these procedures to Java code by completely elimiating functions. And we saw a huge performance bost and less DB load.\nAfter observing DB for few days we took a call to reduce 8xlarge instance to 4xlarge. To our surprise it holded well.\n**Milestone 2\n**Challenge was still not over, we knew that RDS is still can be optmized further consider the load which were handelling. So our next target was DB storage. We observed that 80% of our storage was contributed by one of our audit table which stored request and response of each API call.\nChallenge here was we cannot completely eliminate this table as it was used by many of our teams for analysis purpose. We started to think any alternative DB or storage options like DynamoDB, EFS, CLickhous, S3 etc. After some analysis, we finalized keeping table in RDS itself but the request response part of it in S3. And the reference link to those S3 files in the table. This reduced our table size to good extent.\nWhile analyzing storage issue of audit table we realized that insert was synchronous and it was consuming good amout of CPU. So we made some optimizations to make insertion of it async and batches. To our surprise after release of this to production we saw no significant reduction in CPU utilization.\nAlong with this activity we were doing some optimizations in one of our DB functions. During that we realized lot of frequently used tables miss indexing. So we added indexes in those tables and got a surpise. DB utilization got drastically reduced. So we took call to reduce DB from 4xlarge to 2xlarge.\nMilestone 3\nWe were using postgres version 13. After further discussions with AWS team we got 2 suggestions:\nupgrade to postgres version 15 will give us performance boost.\nThey also suggest to use IO optimized instance considering our workload and activity.\nAs part of milestone 2 we figured out that we need to move older audit data to reduce our storage cost further:\n1. Reduce our Active DB size\nThis was a large activity and need a huge downtime. We took a downtime and executed first 2 activities but movement of audit data was too slow and did not completed on time. So we written script which moved this data in batches. After completing and deletion of old data our active DB size got reduced by 70%.\nOur Learnings:\nDont put load on DB by using lot of DB procedures as its costly.\nFirst thing look for is indexing while doing DB optimizations\nDon’t just focus on CPU of DB. IOPS and Storage cost the most.\n","wordCount":"672","inLanguage":"en","datePublished":"2025-01-23T00:00:00Z","dateModified":"2025-01-23T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://rupeshsharma.in/posts/journey-from-8xlarge-to-2xlarge/"},"publisher":{"@type":"Organization","name":"Software hacks in small packs","logo":{"@type":"ImageObject","url":"https://rupeshsharma.in/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://rupeshsharma.in/ accesskey=h title="Software hacks in small packs (Alt + H)">Software hacks in small packs</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://rupeshsharma.in/ title=Home><span>Home</span></a></li><li><a href=https://rupeshsharma.in/about/ title=About><span>About</span></a></li><li><a href=https://rupeshsharma.in/posts/ title=Blog><span>Blog</span></a></li><li><a href=https://rupeshsharma.in/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://rupeshsharma.in/contact/ title=Contact><span>Contact</span></a></li><li><a href=https://github.com/rupesh137 title=GitHub><span>GitHub</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://www.linkedin.com/in/rupeshsharma137/ title=LinkedIn><span>LinkedIn</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Journey from 8xlarge to 2xlarge</h1><div class=post-meta><span title='2025-01-23 00:00:00 +0000 UTC'>January 23, 2025</span></div></header><div class=post-content><p>There are only 2 ways to make money. Increase your income or reduce your expense. Its true for inidividual as well as organizations. In my current organization we were facing huge challenge of unncessary cost being spent on AWS. We were paying huge chunk of our income to AWS. In this post I am going to disect some critical problems and optimizations done to reduce the cost of the AWS.</p><p><strong>The Begining</strong><br>After realising the problem we formed a team who can solely focus on the AWS cost optimization. I was part of this team and my job was to find out critical bottlenecks and solve them.</p><p>We started with checking our AWS bills and found that majority of cost was contributed by RDS. And that was very evident as we were using RDS 8xlarge machine to process daily of 13K applications. So we shifted our focus on optimizing RDS usage.</p><p>**Milestone 1<br>**We started checking AWS performance insight to get the idea what things are consuming most of RDS CPU. Found that top 10 queries were few functions which are heavily used by the system. To solve this problem we decided to convert these functions procedures to java code.</p><p>We wanted to set some benchmark to verify our changes. So we did a performace setup to validate our changes. And tested it against the current code. Then we started converting these procedures to Java code by completely elimiating functions. And we saw a huge performance bost and less DB load.</p><p>After observing DB for few days we took a call to reduce 8xlarge instance to 4xlarge. To our surprise it holded well.</p><p>**Milestone 2<br>**Challenge was still not over, we knew that RDS is still can be optmized further consider the load which were handelling. So our next target was DB storage. We observed that 80% of our storage was contributed by one of our audit table which stored request and response of each API call.</p><p>Challenge here was we cannot completely eliminate this table as it was used by many of our teams for analysis purpose. We started to think any alternative DB or storage options like DynamoDB, EFS, CLickhous, S3 etc. After some analysis, we finalized keeping table in RDS itself but the request response part of it in S3. And the reference link to those S3 files in the table. This reduced our table size to good extent.</p><p>While analyzing storage issue of audit table we realized that insert was synchronous and it was consuming good amout of CPU. So we made some optimizations to make insertion of it async and batches. To our surprise after release of this to production we saw no significant reduction in CPU utilization.</p><p>Along with this activity we were doing some optimizations in one of our DB functions. During that we realized lot of frequently used tables miss indexing. So we added indexes in those tables and got a surpise. DB utilization got drastically reduced. So we took call to reduce DB from 4xlarge to 2xlarge.</p><p><strong>Milestone 3</strong></p><p>We were using postgres version 13. After further discussions with AWS team we got 2 suggestions:</p><ul><li><p>upgrade to postgres version 15 will give us performance boost.</p></li><li><p>They also suggest to use IO optimized instance considering our workload and activity.</p></li></ul><p>As part of milestone 2 we figured out that we need to move older audit data to reduce our storage cost further:<br>1. Reduce our Active DB size</p><p>This was a large activity and need a huge downtime. We took a downtime and executed first 2 activities but movement of audit data was too slow and did not completed on time. So we written script which moved this data in batches. After completing and deletion of old data our active DB size got reduced by 70%.</p><p><strong>Our Learnings:</strong></p><ol><li><p>Dont put load on DB by using lot of DB procedures as its costly.</p></li><li><p>First thing look for is indexing while doing DB optimizations</p></li><li><p>Don&rsquo;t just focus on CPU of DB. IOPS and Storage cost the most.</p></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://rupeshsharma.in/tags/aws/>Aws</a></li><li><a href=https://rupeshsharma.in/tags/performance/>Performance</a></li><li><a href=https://rupeshsharma.in/tags/pos/>Pos</a></li><li><a href=https://rupeshsharma.in/tags/postgresql/>Postgresql</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://rupeshsharma.in/>Software hacks in small packs</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>